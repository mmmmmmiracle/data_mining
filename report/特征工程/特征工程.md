# 


## ç‰¹å¾å·¥ç¨‹
å¸¸è§çš„ç‰¹å¾å·¥ç¨‹åŒ…æ‹¬ï¼š
1. å¼‚å¸¸å¤„ç†ï¼š
    - é€šè¿‡ç®±çº¿å›¾ï¼ˆæˆ– 3-Sigmaï¼‰åˆ†æåˆ é™¤å¼‚å¸¸å€¼ï¼›
    - BOX-COX è½¬æ¢ï¼ˆå¤„ç†æœ‰ååˆ†å¸ƒï¼‰ï¼›
    - é•¿å°¾æˆªæ–­ï¼›
2. ç‰¹å¾å½’ä¸€åŒ–/æ ‡å‡†åŒ–ï¼š
    - æ ‡å‡†åŒ–ï¼ˆè½¬æ¢ä¸ºæ ‡å‡†æ­£æ€åˆ†å¸ƒï¼‰ï¼›
    - å½’ä¸€åŒ–ï¼ˆæŠ“æ¢åˆ° [0,1] åŒºé—´ï¼‰ï¼›
    - é’ˆå¯¹å¹‚å¾‹åˆ†å¸ƒï¼Œå¯ä»¥é‡‡ç”¨å…¬å¼ï¼š $log(\frac{1+x}{1+median})$
3. æ•°æ®åˆ†æ¡¶ï¼š
    - ç­‰é¢‘åˆ†æ¡¶ï¼›
    - ç­‰è·åˆ†æ¡¶ï¼›
    - Best-KS åˆ†æ¡¶ï¼ˆç±»ä¼¼åˆ©ç”¨åŸºå°¼æŒ‡æ•°è¿›è¡ŒäºŒåˆ†ç±»ï¼‰ï¼›
    - å¡æ–¹åˆ†æ¡¶ï¼›
4. ç¼ºå¤±å€¼å¤„ç†ï¼š
    - ä¸å¤„ç†ï¼ˆé’ˆå¯¹ç±»ä¼¼ XGBoost ç­‰æ ‘æ¨¡å‹ï¼‰ï¼›
    - åˆ é™¤ï¼ˆç¼ºå¤±æ•°æ®å¤ªå¤šï¼‰ï¼›
    - æ’å€¼è¡¥å…¨ï¼ŒåŒ…æ‹¬å‡å€¼/ä¸­ä½æ•°/ä¼—æ•°/å»ºæ¨¡é¢„æµ‹/å¤šé‡æ’è¡¥/å‹ç¼©æ„ŸçŸ¥è¡¥å…¨/çŸ©é˜µè¡¥å…¨ç­‰ï¼›
    - åˆ†ç®±ï¼Œç¼ºå¤±å€¼ä¸€ä¸ªç®±ï¼›
5. ç‰¹å¾æ„é€ ï¼š
    - æ„é€ ç»Ÿè®¡é‡ç‰¹å¾ï¼ŒæŠ¥å‘Šè®¡æ•°ã€æ±‚å’Œã€æ¯”ä¾‹ã€æ ‡å‡†å·®ç­‰ï¼›
    - æ—¶é—´ç‰¹å¾ï¼ŒåŒ…æ‹¬ç›¸å¯¹æ—¶é—´å’Œç»å¯¹æ—¶é—´ï¼ŒèŠ‚å‡æ—¥ï¼ŒåŒä¼‘æ—¥ç­‰ï¼›
    - åœ°ç†ä¿¡æ¯ï¼ŒåŒ…æ‹¬åˆ†ç®±ï¼Œåˆ†å¸ƒç¼–ç ç­‰æ–¹æ³•ï¼›
    - éçº¿æ€§å˜æ¢ï¼ŒåŒ…æ‹¬ log/ å¹³æ–¹/ æ ¹å·ç­‰ï¼›
    - ç‰¹å¾ç»„åˆï¼Œç‰¹å¾äº¤å‰ï¼›
    - ä»è€…è§ä»ï¼Œæ™ºè€…è§æ™ºã€‚
6. ç‰¹å¾ç­›é€‰
    - è¿‡æ»¤å¼ï¼ˆfilterï¼‰ï¼šå…ˆå¯¹æ•°æ®è¿›è¡Œç‰¹å¾é€‰æ‹©ï¼Œç„¶ååœ¨è®­ç»ƒå­¦ä¹ å™¨ï¼Œå¸¸è§çš„æ–¹æ³•æœ‰ Relief/æ–¹å·®é€‰æ‹©å‘/ç›¸å…³ç³»æ•°æ³•/å¡æ–¹æ£€éªŒæ³•/äº’ä¿¡æ¯æ³•ï¼›
    - åŒ…è£¹å¼ï¼ˆwrapperï¼‰ï¼šç›´æ¥æŠŠæœ€ç»ˆå°†è¦ä½¿ç”¨çš„å­¦ä¹ å™¨çš„æ€§èƒ½ä½œä¸ºç‰¹å¾å­é›†çš„è¯„ä»·å‡†åˆ™ï¼Œå¸¸è§æ–¹æ³•æœ‰ LVMï¼ˆLas Vegas Wrapperï¼‰ ï¼›
    - åµŒå…¥å¼ï¼ˆembeddingï¼‰ï¼šç»“åˆè¿‡æ»¤å¼å’ŒåŒ…è£¹å¼ï¼Œå­¦ä¹ å™¨è®­ç»ƒè¿‡ç¨‹ä¸­è‡ªåŠ¨è¿›è¡Œäº†ç‰¹å¾é€‰æ‹©ï¼Œå¸¸è§çš„æœ‰ lasso å›å½’ï¼›
7. é™ç»´
    - PCA/ LDA/ ICAï¼›
    - ç‰¹å¾é€‰æ‹©ä¹Ÿæ˜¯ä¸€ç§é™ç»´ã€‚

## ä»£ç ç¤ºä¾‹

## 0 å¯¼å…¥æ•°æ®


```python
import pandas as pd
import numpy as np
import matplotlib
import matplotlib.pyplot as plt
import seaborn as sns
from operator import itemgetter

%matplotlib inline
```


```python
path = './datalab/231784/'
Train_data = pd.read_csv(path+'used_car_train_20200313.csv', sep=' ')
Test_data = pd.read_csv(path+'used_car_testA_20200313.csv', sep=' ')
print(Train_data.shape)
print(Test_data.shape)
```

    (150000, 31)
    (50000, 30)



```python
Train_data.head()
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }
    .dataframe tbody tr th {
        vertical-align: top;
    }
    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>SaleID</th>
      <th>name</th>
      <th>regDate</th>
      <th>model</th>
      <th>brand</th>
      <th>bodyType</th>
      <th>fuelType</th>
      <th>gearbox</th>
      <th>power</th>
      <th>kilometer</th>
      <th>...</th>
      <th>v_5</th>
      <th>v_6</th>
      <th>v_7</th>
      <th>v_8</th>
      <th>v_9</th>
      <th>v_10</th>
      <th>v_11</th>
      <th>v_12</th>
      <th>v_13</th>
      <th>v_14</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0</td>
      <td>736</td>
      <td>20040402</td>
      <td>30.0</td>
      <td>6</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>60</td>
      <td>12.5</td>
      <td>...</td>
      <td>0.235676</td>
      <td>0.101988</td>
      <td>0.129549</td>
      <td>0.022816</td>
      <td>0.097462</td>
      <td>-2.881803</td>
      <td>2.804097</td>
      <td>-2.420821</td>
      <td>0.795292</td>
      <td>0.914762</td>
    </tr>
    <tr>
      <th>1</th>
      <td>1</td>
      <td>2262</td>
      <td>20030301</td>
      <td>40.0</td>
      <td>1</td>
      <td>2.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0</td>
      <td>15.0</td>
      <td>...</td>
      <td>0.264777</td>
      <td>0.121004</td>
      <td>0.135731</td>
      <td>0.026597</td>
      <td>0.020582</td>
      <td>-4.900482</td>
      <td>2.096338</td>
      <td>-1.030483</td>
      <td>-1.722674</td>
      <td>0.245522</td>
    </tr>
    <tr>
      <th>2</th>
      <td>2</td>
      <td>14874</td>
      <td>20040403</td>
      <td>115.0</td>
      <td>15</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>163</td>
      <td>12.5</td>
      <td>...</td>
      <td>0.251410</td>
      <td>0.114912</td>
      <td>0.165147</td>
      <td>0.062173</td>
      <td>0.027075</td>
      <td>-4.846749</td>
      <td>1.803559</td>
      <td>1.565330</td>
      <td>-0.832687</td>
      <td>-0.229963</td>
    </tr>
    <tr>
      <th>3</th>
      <td>3</td>
      <td>71865</td>
      <td>19960908</td>
      <td>109.0</td>
      <td>10</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>193</td>
      <td>15.0</td>
      <td>...</td>
      <td>0.274293</td>
      <td>0.110300</td>
      <td>0.121964</td>
      <td>0.033395</td>
      <td>0.000000</td>
      <td>-4.509599</td>
      <td>1.285940</td>
      <td>-0.501868</td>
      <td>-2.438353</td>
      <td>-0.478699</td>
    </tr>
    <tr>
      <th>4</th>
      <td>4</td>
      <td>111080</td>
      <td>20120103</td>
      <td>110.0</td>
      <td>5</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>68</td>
      <td>5.0</td>
      <td>...</td>
      <td>0.228036</td>
      <td>0.073205</td>
      <td>0.091880</td>
      <td>0.078819</td>
      <td>0.121534</td>
      <td>-1.896240</td>
      <td>0.910783</td>
      <td>0.931110</td>
      <td>2.834518</td>
      <td>1.923482</td>
    </tr>
  </tbody>
</table>
<p>5 rows Ã— 31 columns</p>
</div>




```python
Train_data.columns
```




    Index(['SaleID', 'name', 'regDate', 'model', 'brand', 'bodyType', 'fuelType',
           'gearbox', 'power', 'kilometer', 'notRepairedDamage', 'regionCode',
           'seller', 'offerType', 'creatDate', 'price', 'v_0', 'v_1', 'v_2', 'v_3',
           'v_4', 'v_5', 'v_6', 'v_7', 'v_8', 'v_9', 'v_10', 'v_11', 'v_12',
           'v_13', 'v_14'],
          dtype='object')




```python
Test_data.columns
```




    Index(['SaleID', 'name', 'regDate', 'model', 'brand', 'bodyType', 'fuelType',
           'gearbox', 'power', 'kilometer', 'notRepairedDamage', 'regionCode',
           'seller', 'offerType', 'creatDate', 'v_0', 'v_1', 'v_2', 'v_3', 'v_4',
           'v_5', 'v_6', 'v_7', 'v_8', 'v_9', 'v_10', 'v_11', 'v_12', 'v_13',
           'v_14'],
          dtype='object')



## 1 åˆ é™¤å¼‚å¸¸å€¼


```python
# è¿™é‡Œæˆ‘åŒ…è£…äº†ä¸€ä¸ªå¼‚å¸¸å€¼å¤„ç†çš„ä»£ç ï¼Œå¯ä»¥éšä¾¿è°ƒç”¨ã€‚
def outliers_proc(data, col_name, scale=3):
    """
    ç”¨äºæ¸…æ´—å¼‚å¸¸å€¼ï¼Œé»˜è®¤ç”¨ box_plotï¼ˆscale=3ï¼‰è¿›è¡Œæ¸…æ´—
    :param data: æ¥æ”¶ pandas æ•°æ®æ ¼å¼
    :param col_name: pandas åˆ—å
    :param scale: å°ºåº¦
    :return:
    """

    def box_plot_outliers(data_ser, box_scale):
        """
        åˆ©ç”¨ç®±çº¿å›¾å»é™¤å¼‚å¸¸å€¼
        :param data_ser: æ¥æ”¶ pandas.Series æ•°æ®æ ¼å¼
        :param box_scale: ç®±çº¿å›¾å°ºåº¦ï¼Œ
        :return:
        """
        iqr = box_scale * (data_ser.quantile(0.75) - data_ser.quantile(0.25))
        val_low = data_ser.quantile(0.25) - iqr
        val_up = data_ser.quantile(0.75) + iqr
        rule_low = (data_ser < val_low)
        rule_up = (data_ser > val_up)
        return (rule_low, rule_up), (val_low, val_up)

    data_n = data.copy()
    data_series = data_n[col_name]
    rule, value = box_plot_outliers(data_series, box_scale=scale)
    index = np.arange(data_series.shape[0])[rule[0] | rule[1]]
    print("Delete number is: {}".format(len(index)))
    data_n = data_n.drop(index)
    data_n.reset_index(drop=True, inplace=True)
    print("Now column number is: {}".format(data_n.shape[0]))
    index_low = np.arange(data_series.shape[0])[rule[0]]
    outliers = data_series.iloc[index_low]
    print("Description of data less than the lower bound is:")
    print(pd.Series(outliers).describe())
    index_up = np.arange(data_series.shape[0])[rule[1]]
    outliers = data_series.iloc[index_up]
    print("Description of data larger than the upper bound is:")
    print(pd.Series(outliers).describe())
    
    fig, ax = plt.subplots(1, 2, figsize=(10, 7))
    sns.boxplot(y=data[col_name], data=data, palette="Set1", ax=ax[0])
    sns.boxplot(y=data_n[col_name], data=data_n, palette="Set1", ax=ax[1])
    return data_n
```


```python
# æˆ‘ä»¬å¯ä»¥åˆ æ‰ä¸€äº›å¼‚å¸¸æ•°æ®ï¼Œä»¥ power ä¸ºä¾‹ã€‚  
# è¿™é‡Œåˆ ä¸åˆ åŒå­¦å¯ä»¥è‡ªè¡Œåˆ¤æ–­
# ä½†æ˜¯è¦æ³¨æ„ test çš„æ•°æ®ä¸èƒ½åˆ  = = ä¸èƒ½æ©è€³ç›—é“ƒæ˜¯ä¸æ˜¯

Train_data = outliers_proc(Train_data, 'power', scale=3)
```

    Delete number is: 963
    Now column number is: 149037
    Description of data less than the lower bound is:
    count    0.0
    mean     NaN
    std      NaN
    min      NaN
    25%      NaN
    50%      NaN
    75%      NaN
    max      NaN
    Name: power, dtype: float64
    Description of data larger than the upper bound is:
    count      963.000000
    mean       846.836968
    std       1929.418081
    min        376.000000
    25%        400.000000
    50%        436.000000
    75%        514.000000
    max      19312.000000
    Name: power, dtype: float64



![png](output_11_1.png)


## 2 ç‰¹å¾æ„é€ 


```python
# è®­ç»ƒé›†å’Œæµ‹è¯•é›†æ”¾åœ¨ä¸€èµ·ï¼Œæ–¹ä¾¿æ„é€ ç‰¹å¾
Train_data['train']=1
Test_data['train']=0
data = pd.concat([Train_data, Test_data], ignore_index=True)
```


```python
# ä½¿ç”¨æ—¶é—´ï¼šdata['creatDate'] - data['regDate']ï¼Œååº”æ±½è½¦ä½¿ç”¨æ—¶é—´ï¼Œä¸€èˆ¬æ¥è¯´ä»·æ ¼ä¸ä½¿ç”¨æ—¶é—´æˆåæ¯”
# ä¸è¿‡è¦æ³¨æ„ï¼Œæ•°æ®é‡Œæœ‰æ—¶é—´å‡ºé”™çš„æ ¼å¼ï¼Œæ‰€ä»¥æˆ‘ä»¬éœ€è¦ errors='coerce'
data['used_time'] = (pd.to_datetime(data['creatDate'], format='%Y%m%d', errors='coerce') - 
                            pd.to_datetime(data['regDate'], format='%Y%m%d', errors='coerce')).dt.days
```


```python
# çœ‹ä¸€ä¸‹ç©ºæ•°æ®ï¼Œæœ‰ 15k ä¸ªæ ·æœ¬çš„æ—¶é—´æ˜¯æœ‰é—®é¢˜çš„ï¼Œæˆ‘ä»¬å¯ä»¥é€‰æ‹©åˆ é™¤ï¼Œä¹Ÿå¯ä»¥é€‰æ‹©æ”¾ç€ã€‚
# ä½†æ˜¯è¿™é‡Œä¸å»ºè®®åˆ é™¤ï¼Œå› ä¸ºåˆ é™¤ç¼ºå¤±æ•°æ®å æ€»æ ·æœ¬é‡è¿‡å¤§ï¼Œ7.5%
# æˆ‘ä»¬å¯ä»¥å…ˆæ”¾ç€ï¼Œå› ä¸ºå¦‚æœæˆ‘ä»¬ XGBoost ä¹‹ç±»çš„å†³ç­–æ ‘ï¼Œå…¶æœ¬èº«å°±èƒ½å¤„ç†ç¼ºå¤±å€¼ï¼Œæ‰€ä»¥å¯ä»¥ä¸ç”¨ç®¡ï¼›
data['used_time'].isnull().sum()
```




    15072




```python
# ä»é‚®ç¼–ä¸­æå–åŸå¸‚ä¿¡æ¯ï¼Œç›¸å½“äºåŠ å…¥äº†å…ˆéªŒçŸ¥è¯†
data['city'] = data['regionCode'].apply(lambda x : str(x)[:-3])
data = data
```


```python
# è®¡ç®—æŸå“ç‰Œçš„é”€å”®ç»Ÿè®¡é‡ï¼ŒåŒå­¦ä»¬è¿˜å¯ä»¥è®¡ç®—å…¶ä»–ç‰¹å¾çš„ç»Ÿè®¡é‡
# è¿™é‡Œè¦ä»¥ train çš„æ•°æ®è®¡ç®—ç»Ÿè®¡é‡
Train_gb = Train_data.groupby("brand")
all_info = {}
for kind, kind_data in Train_gb:
    info = {}
    kind_data = kind_data[kind_data['price'] > 0]
    info['brand_amount'] = len(kind_data)
    info['brand_price_max'] = kind_data.price.max()
    info['brand_price_median'] = kind_data.price.median()
    info['brand_price_min'] = kind_data.price.min()
    info['brand_price_sum'] = kind_data.price.sum()
    info['brand_price_std'] = kind_data.price.std()
    info['brand_price_average'] = round(kind_data.price.sum() / (len(kind_data) + 1), 2)
    all_info[kind] = info
brand_fe = pd.DataFrame(all_info).T.reset_index().rename(columns={"index": "brand"})
data = data.merge(brand_fe, how='left', on='brand')
```


```python
# æ•°æ®åˆ†æ¡¶ ä»¥ power ä¸ºä¾‹
# è¿™æ—¶å€™æˆ‘ä»¬çš„ç¼ºå¤±å€¼ä¹Ÿè¿›æ¡¶äº†ï¼Œ
# ä¸ºä»€ä¹ˆè¦åšæ•°æ®åˆ†æ¡¶å‘¢ï¼ŒåŸå› æœ‰å¾ˆå¤šï¼Œ= =
# 1. ç¦»æ•£åç¨€ç–å‘é‡å†…ç§¯ä¹˜æ³•è¿ç®—é€Ÿåº¦æ›´å¿«ï¼Œè®¡ç®—ç»“æœä¹Ÿæ–¹ä¾¿å­˜å‚¨ï¼Œå®¹æ˜“æ‰©å±•ï¼›
# 2. ç¦»æ•£åçš„ç‰¹å¾å¯¹å¼‚å¸¸å€¼æ›´å…·é²æ£’æ€§ï¼Œå¦‚ age>30 ä¸º 1 å¦åˆ™ä¸º 0ï¼Œå¯¹äºå¹´é¾„ä¸º 200 çš„ä¹Ÿä¸ä¼šå¯¹æ¨¡å‹é€ æˆå¾ˆå¤§çš„å¹²æ‰°ï¼›
# 3. LR å±äºå¹¿ä¹‰çº¿æ€§æ¨¡å‹ï¼Œè¡¨è¾¾èƒ½åŠ›æœ‰é™ï¼Œç»è¿‡ç¦»æ•£åŒ–åï¼Œæ¯ä¸ªå˜é‡æœ‰å•ç‹¬çš„æƒé‡ï¼Œè¿™ç›¸å½“äºå¼•å…¥äº†éçº¿æ€§ï¼Œèƒ½å¤Ÿæå‡æ¨¡å‹çš„è¡¨è¾¾èƒ½åŠ›ï¼ŒåŠ å¤§æ‹Ÿåˆï¼›
# 4. ç¦»æ•£åç‰¹å¾å¯ä»¥è¿›è¡Œç‰¹å¾äº¤å‰ï¼Œæå‡è¡¨è¾¾èƒ½åŠ›ï¼Œç”± M+N ä¸ªå˜é‡ç¼–ç¨‹ M*N ä¸ªå˜é‡ï¼Œè¿›ä¸€æ­¥å¼•å…¥éçº¿å½¢ï¼Œæå‡äº†è¡¨è¾¾èƒ½åŠ›ï¼›
# 5. ç‰¹å¾ç¦»æ•£åæ¨¡å‹æ›´ç¨³å®šï¼Œå¦‚ç”¨æˆ·å¹´é¾„åŒºé—´ï¼Œä¸ä¼šå› ä¸ºç”¨æˆ·å¹´é¾„é•¿äº†ä¸€å²å°±å˜åŒ–

# å½“ç„¶è¿˜æœ‰å¾ˆå¤šåŸå› ï¼ŒLightGBM åœ¨æ”¹è¿› XGBoost æ—¶å°±å¢åŠ äº†æ•°æ®åˆ†æ¡¶ï¼Œå¢å¼ºäº†æ¨¡å‹çš„æ³›åŒ–æ€§

bin = [i*10 for i in range(31)]
data['power_bin'] = pd.cut(data['power'], bin, labels=False)
data[['power_bin', 'power']].head()
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }
    .dataframe tbody tr th {
        vertical-align: top;
    }
    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>power_bin</th>
      <th>power</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>5.0</td>
      <td>60</td>
    </tr>
    <tr>
      <th>1</th>
      <td>NaN</td>
      <td>0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>16.0</td>
      <td>163</td>
    </tr>
    <tr>
      <th>3</th>
      <td>19.0</td>
      <td>193</td>
    </tr>
    <tr>
      <th>4</th>
      <td>6.0</td>
      <td>68</td>
    </tr>
  </tbody>
</table>
</div>




```python
# åˆ é™¤ä¸éœ€è¦çš„æ•°æ®
data = data.drop(['creatDate', 'regDate', 'regionCode'], axis=1)
```


```python
print(data.shape)
data.columns
```

    (199037, 39)





    Index(['SaleID', 'bodyType', 'brand', 'fuelType', 'gearbox', 'kilometer',
           'model', 'name', 'notRepairedDamage', 'offerType', 'power', 'price',
           'seller', 'train', 'v_0', 'v_1', 'v_10', 'v_11', 'v_12', 'v_13', 'v_14',
           'v_2', 'v_3', 'v_4', 'v_5', 'v_6', 'v_7', 'v_8', 'v_9', 'used_time',
           'city', 'brand_amount', 'brand_price_average', 'brand_price_max',
           'brand_price_median', 'brand_price_min', 'brand_price_std',
           'brand_price_sum', 'power_bin'],
          dtype='object')




```python
# ç›®å‰çš„æ•°æ®å…¶å®å·²ç»å¯ä»¥ç»™æ ‘æ¨¡å‹ä½¿ç”¨äº†ï¼Œæ‰€ä»¥æˆ‘ä»¬å¯¼å‡ºä¸€ä¸‹
data.to_csv('data_for_tree.csv', index=0)
```


```python
# æˆ‘ä»¬å¯ä»¥å†æ„é€ ä¸€ä»½ç‰¹å¾ç»™ LR NN ä¹‹ç±»çš„æ¨¡å‹ç”¨
# ä¹‹æ‰€ä»¥åˆ†å¼€æ„é€ æ˜¯å› ä¸ºï¼Œä¸åŒæ¨¡å‹å¯¹æ•°æ®é›†çš„è¦æ±‚ä¸åŒ
# æˆ‘ä»¬çœ‹ä¸‹æ•°æ®åˆ†å¸ƒï¼š
data['power'].plot.hist()
```




    <matplotlib.axes._subplots.AxesSubplot at 0x7fe026cf0c18>




![png](output_22_1.png)



```python
# æˆ‘ä»¬åˆšåˆšå·²ç»å¯¹ train è¿›è¡Œå¼‚å¸¸å€¼å¤„ç†äº†ï¼Œä½†æ˜¯ç°åœ¨è¿˜æœ‰è¿™ä¹ˆå¥‡æ€ªçš„åˆ†å¸ƒæ˜¯å› ä¸º test ä¸­çš„ power å¼‚å¸¸å€¼ï¼Œ
# æ‰€ä»¥æˆ‘ä»¬å…¶å®åˆšåˆš train ä¸­çš„ power å¼‚å¸¸å€¼ä¸åˆ ä¸ºå¥½ï¼Œå¯ä»¥ç”¨é•¿å°¾åˆ†å¸ƒæˆªæ–­æ¥ä»£æ›¿
Train_data['power'].plot.hist()
```




    <matplotlib.axes._subplots.AxesSubplot at 0x7fe02d7a8eb8>




![png](output_23_1.png)



```python
# æˆ‘ä»¬å¯¹å…¶å– logï¼Œåœ¨åšå½’ä¸€åŒ–
from sklearn import preprocessing
min_max_scaler = preprocessing.MinMaxScaler()
data['power'] = np.log(data['power'] + 1) 
data['power'] = ((data['power'] - np.min(data['power'])) / (np.max(data['power']) - np.min(data['power'])))
data['power'].plot.hist()
```




    <matplotlib.axes._subplots.AxesSubplot at 0x7fe026c342b0>




![png](output_24_1.png)



```python
# km çš„æ¯”è¾ƒæ­£å¸¸ï¼Œåº”è¯¥æ˜¯å·²ç»åšè¿‡åˆ†æ¡¶äº†
data['kilometer'].plot.hist()
```




    <matplotlib.axes._subplots.AxesSubplot at 0x7fe029ad2080>




![png](output_25_1.png)



```python
# æ‰€ä»¥æˆ‘ä»¬å¯ä»¥ç›´æ¥åšå½’ä¸€åŒ–
data['kilometer'] = ((data['kilometer'] - np.min(data['kilometer'])) / 
                        (np.max(data['kilometer']) - np.min(data['kilometer'])))
data['kilometer'].plot.hist()
```




    <matplotlib.axes._subplots.AxesSubplot at 0x7fe029b1d668>




![png](output_26_1.png)



```python
# é™¤æ­¤ä¹‹å¤– è¿˜æœ‰æˆ‘ä»¬åˆšåˆšæ„é€ çš„ç»Ÿè®¡é‡ç‰¹å¾ï¼š
# 'brand_amount', 'brand_price_average', 'brand_price_max',
# 'brand_price_median', 'brand_price_min', 'brand_price_std',
# 'brand_price_sum'
# è¿™é‡Œä¸å†ä¸€ä¸€ä¸¾ä¾‹åˆ†æäº†ï¼Œç›´æ¥åšå˜æ¢ï¼Œ
def max_min(x):
    return (x - np.min(x)) / (np.max(x) - np.min(x))

data['brand_amount'] = ((data['brand_amount'] - np.min(data['brand_amount'])) / 
                        (np.max(data['brand_amount']) - np.min(data['brand_amount'])))
data['brand_price_average'] = ((data['brand_price_average'] - np.min(data['brand_price_average'])) / 
                               (np.max(data['brand_price_average']) - np.min(data['brand_price_average'])))
data['brand_price_max'] = ((data['brand_price_max'] - np.min(data['brand_price_max'])) / 
                           (np.max(data['brand_price_max']) - np.min(data['brand_price_max'])))
data['brand_price_median'] = ((data['brand_price_median'] - np.min(data['brand_price_median'])) /
                              (np.max(data['brand_price_median']) - np.min(data['brand_price_median'])))
data['brand_price_min'] = ((data['brand_price_min'] - np.min(data['brand_price_min'])) / 
                           (np.max(data['brand_price_min']) - np.min(data['brand_price_min'])))
data['brand_price_std'] = ((data['brand_price_std'] - np.min(data['brand_price_std'])) / 
                           (np.max(data['brand_price_std']) - np.min(data['brand_price_std'])))
data['brand_price_sum'] = ((data['brand_price_sum'] - np.min(data['brand_price_sum'])) / 
                           (np.max(data['brand_price_sum']) - np.min(data['brand_price_sum'])))
```


```python
# å¯¹ç±»åˆ«ç‰¹å¾è¿›è¡Œ OneEncoder
data = pd.get_dummies(data, columns=['model', 'brand', 'bodyType', 'fuelType',
                                     'gearbox', 'notRepairedDamage', 'power_bin'])
```


```python
print(data.shape)
data.columns
```

    (199037, 370)





    Index(['SaleID', 'kilometer', 'name', 'offerType', 'power', 'price', 'seller',
           'train', 'v_0', 'v_1',
           ...
           'power_bin_20.0', 'power_bin_21.0', 'power_bin_22.0', 'power_bin_23.0',
           'power_bin_24.0', 'power_bin_25.0', 'power_bin_26.0', 'power_bin_27.0',
           'power_bin_28.0', 'power_bin_29.0'],
          dtype='object', length=370)




```python
# è¿™ä»½æ•°æ®å¯ä»¥ç»™ LR ç”¨
data.to_csv('data_for_lr.csv', index=0)
```

## 3 ç‰¹å¾ç­›é€‰

### 1) è¿‡æ»¤å¼


```python
# ç›¸å…³æ€§åˆ†æ
print(data['power'].corr(data['price'], method='spearman'))
print(data['kilometer'].corr(data['price'], method='spearman'))
print(data['brand_amount'].corr(data['price'], method='spearman'))
print(data['brand_price_average'].corr(data['price'], method='spearman'))
print(data['brand_price_max'].corr(data['price'], method='spearman'))
print(data['brand_price_median'].corr(data['price'], method='spearman'))
```

    0.572828519605
    -0.408256970162
    0.0581566100256
    0.383490957606
    0.259066833881
    0.386910423934



```python
# å½“ç„¶ä¹Ÿå¯ä»¥ç›´æ¥çœ‹å›¾
data_numeric = data[['power', 'kilometer', 'brand_amount', 'brand_price_average', 
                     'brand_price_max', 'brand_price_median']]
correlation = data_numeric.corr()

f , ax = plt.subplots(figsize = (7, 7))
plt.title('Correlation of Numeric Features with Price',y=1,size=16)
sns.heatmap(correlation,square = True,  vmax=0.8)
```




    <matplotlib.axes._subplots.AxesSubplot at 0x7fe0283a6dd8>




![png](output_34_1.png)


### 2) åŒ…è£¹å¼


```python
!pip install mlxtend  # ä¸è¦ç‚¹ï¼Œä¸‹è½½é€Ÿåº¦å¾ˆæ…¢
```

    Collecting mlxtend
    [?25l  Downloading https://files.pythonhosted.org/packages/64/e2/1610a86284029abcad0ac9bc86cb19f9787fe6448ede467188b2a5121bb4/mlxtend-0.17.2-py2.py3-none-any.whl (1.3MB)
    [K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.3MB 7.4kB/s 
    [?25hCollecting scikit-learn>=0.20.3 (from mlxtend)
    [?25l  Downloading https://files.pythonhosted.org/packages/5e/d8/312e03adf4c78663e17d802fe2440072376fee46cada1404f1727ed77a32/scikit_learn-0.22.2.post1-cp36-cp36m-manylinux1_x86_64.whl (7.1MB)
    [K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7.1MB 9.7kB/s 
    [?25hCollecting joblib>=0.13.2 (from mlxtend)
    [?25l  Downloading https://files.pythonhosted.org/packages/28/5c/cf6a2b65a321c4a209efcdf64c2689efae2cb62661f8f6f4bb28547cf1bf/joblib-0.14.1-py2.py3-none-any.whl (294kB)
    [K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 296kB 9.1kB/s 
    [?25hCollecting scipy>=1.2.1 (from mlxtend)
    [?25l  Downloading https://files.pythonhosted.org/packages/dc/29/162476fd44203116e7980cfbd9352eef9db37c49445d1fec35509022f6aa/scipy-1.4.1-cp36-cp36m-manylinux1_x86_64.whl (26.1MB)
    [K     |â–                               | 276kB 11kB/s eta 0:37:33^C
    
    [31mERROR: Operation cancelled by user[0m
    [?25h


```python
# k_feature å¤ªå¤§ä¼šå¾ˆéš¾è·‘ï¼Œæ²¡æœåŠ¡å™¨ï¼Œæ‰€ä»¥æå‰ interrupt äº†
from mlxtend.feature_selection import SequentialFeatureSelector as SFS
from sklearn.linear_model import LinearRegression
sfs = SFS(LinearRegression(),
           k_features=10,
           forward=True,
           floating=False,
           scoring = 'r2',
           cv = 0)
x = data.drop(['price'], axis=1)
x = x.fillna(0)
y = data['price']
sfs.fit(x, y)
sfs.k_feature_names_ 
```


```python
# ç”»å‡ºæ¥ï¼Œå¯ä»¥çœ‹åˆ°è¾¹é™…æ•ˆç›Š
from mlxtend.plotting import plot_sequential_feature_selection as plot_sfs
import matplotlib.pyplot as plt
fig1 = plot_sfs(sfs.get_metric_dict(), kind='std_dev')
plt.grid()
plt.show()
```

### 3) åµŒå…¥å¼


```python
# ä¸‹ä¸€ç« ä»‹ç»ï¼ŒLasso å›å½’å’Œå†³ç­–æ ‘å¯ä»¥å®ŒæˆåµŒå…¥å¼ç‰¹å¾é€‰æ‹©
# å¤§éƒ¨åˆ†æƒ…å†µä¸‹éƒ½æ˜¯ç”¨åµŒå…¥å¼åšç‰¹å¾ç­›é€‰
```

## 4 ç»éªŒæ€»ç»“

ç‰¹å¾å·¥ç¨‹æ˜¯æ¯”èµ›ä¸­æœ€è‡³å…³é‡è¦çš„çš„ä¸€å—ï¼Œç‰¹åˆ«çš„ä¼ ç»Ÿçš„æ¯”èµ›ï¼Œå¤§å®¶çš„æ¨¡å‹å¯èƒ½éƒ½å·®ä¸å¤šï¼Œè°ƒå‚å¸¦æ¥çš„æ•ˆæœå¢å¹…æ˜¯éå¸¸æœ‰é™çš„ï¼Œä½†ç‰¹å¾å·¥ç¨‹çš„å¥½åå¾€å¾€ä¼šå†³å®šäº†æœ€ç»ˆçš„æ’åå’Œæˆç»©ã€‚

ç‰¹å¾å·¥ç¨‹çš„ä¸»è¦ç›®çš„è¿˜æ˜¯åœ¨äºå°†æ•°æ®è½¬æ¢ä¸ºèƒ½æ›´å¥½åœ°è¡¨ç¤ºæ½œåœ¨é—®é¢˜çš„ç‰¹å¾ï¼Œä»è€Œæé«˜æœºå™¨å­¦ä¹ çš„æ€§èƒ½ã€‚æ¯”å¦‚ï¼Œå¼‚å¸¸å€¼å¤„ç†æ˜¯ä¸ºäº†å»é™¤å™ªå£°ï¼Œå¡«è¡¥ç¼ºå¤±å€¼å¯ä»¥åŠ å…¥å…ˆéªŒçŸ¥è¯†ç­‰ã€‚

ç‰¹å¾æ„é€ ä¹Ÿå±äºç‰¹å¾å·¥ç¨‹çš„ä¸€éƒ¨åˆ†ï¼Œå…¶ç›®çš„æ˜¯ä¸ºäº†å¢å¼ºæ•°æ®çš„è¡¨è¾¾ã€‚

æœ‰äº›æ¯”èµ›çš„ç‰¹å¾æ˜¯åŒ¿åç‰¹å¾ï¼Œè¿™å¯¼è‡´æˆ‘ä»¬å¹¶ä¸æ¸…æ¥šç‰¹å¾ç›¸äº’ç›´æ¥çš„å…³è”æ€§ï¼Œè¿™æ—¶æˆ‘ä»¬å°±åªæœ‰å•çº¯åŸºäºç‰¹å¾è¿›è¡Œå¤„ç†ï¼Œæ¯”å¦‚è£…ç®±ï¼Œgroupbyï¼Œagg ç­‰è¿™æ ·ä¸€äº›æ“ä½œè¿›è¡Œä¸€äº›ç‰¹å¾ç»Ÿè®¡ï¼Œæ­¤å¤–è¿˜å¯ä»¥å¯¹ç‰¹å¾è¿›è¡Œè¿›ä¸€æ­¥çš„ logï¼Œexp ç­‰å˜æ¢ï¼Œæˆ–è€…å¯¹å¤šä¸ªç‰¹å¾è¿›è¡Œå››åˆ™è¿ç®—ï¼ˆå¦‚ä¸Šé¢æˆ‘ä»¬ç®—å‡ºçš„ä½¿ç”¨æ—¶é•¿ï¼‰ï¼Œå¤šé¡¹å¼ç»„åˆç­‰ç„¶åè¿›è¡Œç­›é€‰ã€‚ç”±äºç‰¹æ€§çš„åŒ¿åæ€§å…¶å®é™åˆ¶äº†å¾ˆå¤šå¯¹äºç‰¹å¾çš„å¤„ç†ï¼Œå½“ç„¶æœ‰äº›æ—¶å€™ç”¨ NN å»æå–ä¸€äº›ç‰¹å¾ä¹Ÿä¼šè¾¾åˆ°æ„æƒ³ä¸åˆ°çš„è‰¯å¥½æ•ˆæœã€‚

å¯¹äºçŸ¥é“ç‰¹å¾å«ä¹‰ï¼ˆéåŒ¿åï¼‰çš„ç‰¹å¾å·¥ç¨‹ï¼Œç‰¹åˆ«æ˜¯åœ¨å·¥ä¸šç±»å‹æ¯”èµ›ä¸­ï¼Œä¼šåŸºäºä¿¡å·å¤„ç†ï¼Œé¢‘åŸŸæå–ï¼Œä¸°åº¦ï¼Œååº¦ç­‰æ„å»ºæ›´ä¸ºæœ‰å®é™…æ„ä¹‰çš„ç‰¹å¾ï¼Œè¿™å°±æ˜¯ç»“åˆèƒŒæ™¯çš„ç‰¹å¾æ„å»ºï¼Œåœ¨æ¨èç³»ç»Ÿä¸­ä¹Ÿæ˜¯è¿™æ ·çš„ï¼Œå„ç§ç±»å‹ç‚¹å‡»ç‡ç»Ÿè®¡ï¼Œå„æ—¶æ®µç»Ÿè®¡ï¼ŒåŠ ç”¨æˆ·å±æ€§çš„ç»Ÿè®¡ç­‰ç­‰ï¼Œè¿™æ ·ä¸€ç§ç‰¹å¾æ„å»ºå¾€å¾€è¦æ·±å…¥åˆ†æèƒŒåçš„ä¸šåŠ¡é€»è¾‘æˆ–è€…è¯´ç‰©ç†åŸç†ï¼Œä»è€Œæ‰èƒ½æ›´å¥½çš„æ‰¾åˆ° magicã€‚

å½“ç„¶ç‰¹å¾å·¥ç¨‹å…¶å®æ˜¯å’Œæ¨¡å‹ç»“åˆåœ¨ä¸€èµ·çš„ï¼Œè¿™å°±æ˜¯ä¸ºä»€ä¹ˆè¦ä¸º LR NN åšåˆ†æ¡¶å’Œç‰¹å¾å½’ä¸€åŒ–çš„åŸå› ï¼Œè€Œå¯¹äºç‰¹å¾çš„å¤„ç†æ•ˆæœå’Œç‰¹å¾é‡è¦æ€§ç­‰å¾€å¾€è¦é€šè¿‡æ¨¡å‹æ¥éªŒè¯ã€‚

æ€»çš„æ¥è¯´ï¼Œç‰¹å¾å·¥ç¨‹æ˜¯ä¸€ä¸ªå…¥é—¨ç®€å•ï¼Œä½†æƒ³ç²¾é€šéå¸¸éš¾çš„ä¸€ä»¶äº‹ã€‚
